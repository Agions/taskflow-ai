/**
 * TaskFlow AI MCP æœåŠ¡å™¨æ€§èƒ½ç›‘æ§å’Œè¯Šæ–­
 * æä¾›å®Œæ•´çš„æ€§èƒ½ç›‘æ§ã€æŒ‡æ ‡æ”¶é›†å’Œé—®é¢˜è¯Šæ–­åŠŸèƒ½
 */

import { EventEmitter } from 'events';
import { performance } from 'perf_hooks';
import { ConfigManager } from '../../infrastructure/config/manager';
import { CacheManager } from '../../infrastructure/storage/cache';

export interface PerformanceMetrics {
  serverId: string;
  timestamp: Date;
  cpu: CPUMetrics;
  memory: MemoryMetrics;
  network: NetworkMetrics;
  requests: RequestMetrics;
  errors: ErrorMetrics;
  latency: LatencyMetrics;
  throughput: ThroughputMetrics;
}

export interface CPUMetrics {
  usage: number; // ç™¾åˆ†æ¯”
  loadAverage: number[];
  processes: number;
}

export interface MemoryMetrics {
  used: number; // å­—èŠ‚
  total: number; // å­—èŠ‚
  usage: number; // ç™¾åˆ†æ¯”
  heap: {
    used: number;
    total: number;
    limit: number;
  };
  gc: {
    collections: number;
    duration: number;
  };
}

export interface NetworkMetrics {
  bytesIn: number;
  bytesOut: number;
  packetsIn: number;
  packetsOut: number;
  connections: {
    active: number;
    idle: number;
    failed: number;
  };
}

export interface RequestMetrics {
  total: number;
  successful: number;
  failed: number;
  rate: number; // æ¯ç§’è¯·æ±‚æ•°
  averageSize: number;
}

export interface ErrorMetrics {
  total: number;
  rate: number; // é”™è¯¯ç‡
  types: Record<string, number>;
  recent: ErrorEvent[];
}

export interface LatencyMetrics {
  min: number;
  max: number;
  avg: number;
  p50: number;
  p95: number;
  p99: number;
}

export interface ThroughputMetrics {
  requestsPerSecond: number;
  bytesPerSecond: number;
  operationsPerSecond: number;
}

export interface ErrorEvent {
  timestamp: Date;
  type: string;
  message: string;
  stack?: string;
  context?: Record<string, any>;
}

export interface PerformanceAlert {
  id: string;
  serverId: string;
  type: 'cpu' | 'memory' | 'latency' | 'error_rate' | 'throughput';
  severity: 'info' | 'warning' | 'critical';
  message: string;
  threshold: number;
  currentValue: number;
  timestamp: Date;
  resolved?: boolean;
}

export interface DiagnosticReport {
  serverId: string;
  timestamp: Date;
  summary: {
    status: 'healthy' | 'degraded' | 'unhealthy';
    score: number; // 0-100
    issues: number;
  };
  performance: {
    bottlenecks: Bottleneck[];
    recommendations: string[];
    trends: PerformanceTrend[];
  };
  health: {
    checks: HealthCheck[];
    warnings: string[];
    errors: string[];
  };
  resources: {
    utilization: ResourceUtilization;
    capacity: ResourceCapacity;
    predictions: ResourcePrediction[];
  };
}

export interface Bottleneck {
  type: string;
  description: string;
  impact: 'low' | 'medium' | 'high';
  suggestion: string;
}

export interface PerformanceTrend {
  metric: string;
  direction: 'improving' | 'stable' | 'degrading';
  change: number; // ç™¾åˆ†æ¯”å˜åŒ–
  period: string;
}

export interface HealthCheck {
  name: string;
  status: 'pass' | 'warn' | 'fail';
  message: string;
  duration: number;
}

export interface ResourceUtilization {
  cpu: number;
  memory: number;
  disk: number;
  network: number;
}

export interface ResourceCapacity {
  cpu: { current: number; max: number; };
  memory: { current: number; max: number; };
  disk: { current: number; max: number; };
  network: { current: number; max: number; };
}

export interface ResourcePrediction {
  resource: string;
  timeToCapacity: number; // å°æ—¶
  confidence: number; // 0-1
  recommendation: string;
}

/**
 * MCPæœåŠ¡å™¨æ€§èƒ½ç›‘æ§å™¨
 */
export class MCPPerformanceMonitor extends EventEmitter {
  private metrics = new Map<string, PerformanceMetrics[]>();
  private alerts = new Map<string, PerformanceAlert[]>();
  private monitoringIntervals = new Map<string, NodeJS.Timeout>();
  private configManager: ConfigManager;
  private cacheManager: CacheManager;
  private config: MonitoringConfig;

  constructor(
    configManager: ConfigManager, 
    cacheManager: CacheManager,
    config?: Partial<MonitoringConfig>
  ) {
    super();
    this.configManager = configManager;
    this.cacheManager = cacheManager;
    
    this.config = {
      collectInterval: 5000, // 5ç§’
      retentionPeriod: 86400000, // 24å°æ—¶
      alertThresholds: {
        cpu: 80,
        memory: 85,
        latency: 1000, // 1ç§’
        errorRate: 5, // 5%
        throughput: 100 // æœ€å°RPS
      },
      enableDetailedMetrics: true,
      enablePredictions: true,
      ...config
    };
  }

  /**
   * å¼€å§‹ç›‘æ§æœåŠ¡å™¨
   */
  startMonitoring(serverId: string): void {
    if (this.monitoringIntervals.has(serverId)) {
      console.warn(`æœåŠ¡å™¨ç›‘æ§å·²å¯åŠ¨: ${serverId}`);
      return;
    }

    console.log(`ğŸ“Š å¼€å§‹ç›‘æ§MCPæœåŠ¡å™¨: ${serverId}`);

    const interval = setInterval(async () => {
      try {
        await this.collectMetrics(serverId);
      } catch (error) {
        console.error(`æ”¶é›†æŒ‡æ ‡å¤±è´¥: ${serverId}`, error);
      }
    }, this.config.collectInterval);

    this.monitoringIntervals.set(serverId, interval);
    this.emit('monitoringStarted', serverId);
  }

  /**
   * åœæ­¢ç›‘æ§æœåŠ¡å™¨
   */
  stopMonitoring(serverId: string): void {
    const interval = this.monitoringIntervals.get(serverId);
    if (interval) {
      clearInterval(interval);
      this.monitoringIntervals.delete(serverId);
      
      console.log(`â¹ï¸ åœæ­¢ç›‘æ§MCPæœåŠ¡å™¨: ${serverId}`);
      this.emit('monitoringStopped', serverId);
    }
  }

  /**
   * è·å–æœåŠ¡å™¨æ€§èƒ½æŒ‡æ ‡
   */
  getMetrics(serverId: string, timeRange?: { start: Date; end: Date }): PerformanceMetrics[] {
    const serverMetrics = this.metrics.get(serverId) || [];
    
    if (!timeRange) {
      return serverMetrics.slice(-100); // è¿”å›æœ€è¿‘100ä¸ªæŒ‡æ ‡
    }

    return serverMetrics.filter(metric => 
      metric.timestamp >= timeRange.start && metric.timestamp <= timeRange.end
    );
  }

  /**
   * è·å–å®æ—¶æŒ‡æ ‡
   */
  async getRealTimeMetrics(serverId: string): Promise<PerformanceMetrics | null> {
    try {
      return await this.collectMetrics(serverId);
    } catch (error) {
      console.error(`è·å–å®æ—¶æŒ‡æ ‡å¤±è´¥: ${serverId}`, error);
      return null;
    }
  }

  /**
   * ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
   */
  async generateDiagnosticReport(serverId: string): Promise<DiagnosticReport> {
    console.log(`ğŸ” ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š: ${serverId}`);

    const recentMetrics = this.getMetrics(serverId).slice(-20);
    const currentMetrics = recentMetrics[recentMetrics.length - 1];
    
    if (!currentMetrics) {
      throw new Error(`æ²¡æœ‰å¯ç”¨çš„æ€§èƒ½æŒ‡æ ‡: ${serverId}`);
    }

    const report: DiagnosticReport = {
      serverId,
      timestamp: new Date(),
      summary: await this.generateSummary(recentMetrics),
      performance: await this.analyzePerformance(recentMetrics),
      health: await this.performHealthChecks(serverId),
      resources: await this.analyzeResources(recentMetrics)
    };

    // ç¼“å­˜æŠ¥å‘Š
    await this.cacheManager.set(`diagnostic:${serverId}`, report, 3600);

    console.log(`âœ… è¯Šæ–­æŠ¥å‘Šç”Ÿæˆå®Œæˆ: ${serverId}`);
    return report;
  }

  /**
   * è·å–æ€§èƒ½è­¦æŠ¥
   */
  getAlerts(serverId: string, activeOnly: boolean = true): PerformanceAlert[] {
    const serverAlerts = this.alerts.get(serverId) || [];
    
    if (activeOnly) {
      return serverAlerts.filter(alert => !alert.resolved);
    }
    
    return serverAlerts;
  }

  /**
   * è§£å†³è­¦æŠ¥
   */
  resolveAlert(serverId: string, alertId: string): void {
    const serverAlerts = this.alerts.get(serverId) || [];
    const alert = serverAlerts.find(a => a.id === alertId);
    
    if (alert) {
      alert.resolved = true;
      this.emit('alertResolved', alert);
      console.log(`âœ… è­¦æŠ¥å·²è§£å†³: ${alertId}`);
    }
  }

  /**
   * å…³é—­ç›‘æ§å™¨
   */
  async shutdown(): Promise<void> {
    console.log('ğŸ”„ å…³é—­æ€§èƒ½ç›‘æ§å™¨...');

    // åœæ­¢æ‰€æœ‰ç›‘æ§
    for (const serverId of this.monitoringIntervals.keys()) {
      this.stopMonitoring(serverId);
    }

    // ä¿å­˜æŒ‡æ ‡æ•°æ®
    await this.saveMetrics();

    console.log('âœ… æ€§èƒ½ç›‘æ§å™¨å·²å…³é—­');
  }

  // ç§æœ‰æ–¹æ³•

  private async collectMetrics(serverId: string): Promise<PerformanceMetrics> {
    const startTime = performance.now();

    const metrics: PerformanceMetrics = {
      serverId,
      timestamp: new Date(),
      cpu: await this.collectCPUMetrics(),
      memory: await this.collectMemoryMetrics(),
      network: await this.collectNetworkMetrics(serverId),
      requests: await this.collectRequestMetrics(serverId),
      errors: await this.collectErrorMetrics(serverId),
      latency: await this.collectLatencyMetrics(serverId),
      throughput: await this.collectThroughputMetrics(serverId)
    };

    // å­˜å‚¨æŒ‡æ ‡
    const serverMetrics = this.metrics.get(serverId) || [];
    serverMetrics.push(metrics);

    // é™åˆ¶å­˜å‚¨æ•°é‡
    if (serverMetrics.length > 1000) {
      serverMetrics.splice(0, serverMetrics.length - 1000);
    }

    this.metrics.set(serverId, serverMetrics);

    // æ£€æŸ¥è­¦æŠ¥
    await this.checkAlerts(serverId, metrics);

    // æ¸…ç†è¿‡æœŸæŒ‡æ ‡
    await this.cleanupOldMetrics();

    const collectTime = performance.now() - startTime;
    if (collectTime > 1000) {
      console.warn(`æŒ‡æ ‡æ”¶é›†è€—æ—¶è¿‡é•¿: ${serverId} (${collectTime.toFixed(2)}ms)`);
    }

    return metrics;
  }

  private async collectCPUMetrics(): Promise<CPUMetrics> {
    // ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨ç³»ç»Ÿè°ƒç”¨è·å–çœŸå®CPUæ•°æ®
    return {
      usage: Math.random() * 100,
      loadAverage: [1.2, 1.5, 1.8],
      processes: Math.floor(Math.random() * 50) + 10
    };
  }

  private async collectMemoryMetrics(): Promise<MemoryMetrics> {
    const memUsage = process.memoryUsage();
    
    return {
      used: memUsage.rss,
      total: memUsage.rss + 100 * 1024 * 1024, // å‡è®¾æ€»å†…å­˜
      usage: (memUsage.rss / (memUsage.rss + 100 * 1024 * 1024)) * 100,
      heap: {
        used: memUsage.heapUsed,
        total: memUsage.heapTotal,
        limit: memUsage.heapTotal * 2
      },
      gc: {
        collections: 0, // éœ€è¦é›†æˆGCç›‘æ§
        duration: 0
      }
    };
  }

  private async collectNetworkMetrics(serverId: string): Promise<NetworkMetrics> {
    // ç®€åŒ–å®ç°
    return {
      bytesIn: Math.floor(Math.random() * 10000),
      bytesOut: Math.floor(Math.random() * 5000),
      packetsIn: Math.floor(Math.random() * 100),
      packetsOut: Math.floor(Math.random() * 50),
      connections: {
        active: Math.floor(Math.random() * 10),
        idle: Math.floor(Math.random() * 5),
        failed: Math.floor(Math.random() * 2)
      }
    };
  }

  private async collectRequestMetrics(serverId: string): Promise<RequestMetrics> {
    // è¿™é‡Œåº”è¯¥ä»å®é™…çš„MCPæœåŠ¡å™¨è·å–è¯·æ±‚ç»Ÿè®¡
    return {
      total: Math.floor(Math.random() * 1000),
      successful: Math.floor(Math.random() * 950),
      failed: Math.floor(Math.random() * 50),
      rate: Math.random() * 100,
      averageSize: Math.random() * 1024
    };
  }

  private async collectErrorMetrics(serverId: string): Promise<ErrorMetrics> {
    return {
      total: Math.floor(Math.random() * 10),
      rate: Math.random() * 5,
      types: {
        'connection_error': Math.floor(Math.random() * 3),
        'timeout_error': Math.floor(Math.random() * 2),
        'validation_error': Math.floor(Math.random() * 5)
      },
      recent: []
    };
  }

  private async collectLatencyMetrics(serverId: string): Promise<LatencyMetrics> {
    const base = Math.random() * 100;
    return {
      min: base,
      max: base * 5,
      avg: base * 2,
      p50: base * 1.5,
      p95: base * 3,
      p99: base * 4
    };
  }

  private async collectThroughputMetrics(serverId: string): Promise<ThroughputMetrics> {
    return {
      requestsPerSecond: Math.random() * 200,
      bytesPerSecond: Math.random() * 1024 * 1024,
      operationsPerSecond: Math.random() * 150
    };
  }

  private async checkAlerts(serverId: string, metrics: PerformanceMetrics): Promise<void> {
    const serverAlerts = this.alerts.get(serverId) || [];

    // CPU è­¦æŠ¥
    if (metrics.cpu.usage > this.config.alertThresholds.cpu) {
      const alert: PerformanceAlert = {
        id: `cpu_${Date.now()}`,
        serverId,
        type: 'cpu',
        severity: metrics.cpu.usage > 95 ? 'critical' : 'warning',
        message: `CPUä½¿ç”¨ç‡è¿‡é«˜: ${metrics.cpu.usage.toFixed(1)}%`,
        threshold: this.config.alertThresholds.cpu,
        currentValue: metrics.cpu.usage,
        timestamp: new Date()
      };
      
      serverAlerts.push(alert);
      this.emit('alert', alert);
    }

    // å†…å­˜è­¦æŠ¥
    if (metrics.memory.usage > this.config.alertThresholds.memory) {
      const alert: PerformanceAlert = {
        id: `memory_${Date.now()}`,
        serverId,
        type: 'memory',
        severity: metrics.memory.usage > 95 ? 'critical' : 'warning',
        message: `å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: ${metrics.memory.usage.toFixed(1)}%`,
        threshold: this.config.alertThresholds.memory,
        currentValue: metrics.memory.usage,
        timestamp: new Date()
      };
      
      serverAlerts.push(alert);
      this.emit('alert', alert);
    }

    this.alerts.set(serverId, serverAlerts);
  }

  private async generateSummary(metrics: PerformanceMetrics[]): Promise<DiagnosticReport['summary']> {
    if (metrics.length === 0) {
      return { status: 'unhealthy', score: 0, issues: 1 };
    }

    const latest = metrics[metrics.length - 1];
    let score = 100;
    let issues = 0;

    // è¯„ä¼°CPU
    if (latest.cpu.usage > 80) {
      score -= 20;
      issues++;
    }

    // è¯„ä¼°å†…å­˜
    if (latest.memory.usage > 85) {
      score -= 25;
      issues++;
    }

    // è¯„ä¼°å»¶è¿Ÿ
    if (latest.latency.avg > 1000) {
      score -= 15;
      issues++;
    }

    // è¯„ä¼°é”™è¯¯ç‡
    if (latest.errors.rate > 5) {
      score -= 30;
      issues++;
    }

    let status: 'healthy' | 'degraded' | 'unhealthy';
    if (score >= 80) {
      status = 'healthy';
    } else if (score >= 50) {
      status = 'degraded';
    } else {
      status = 'unhealthy';
    }

    return { status, score: Math.max(0, score), issues };
  }

  private async analyzePerformance(metrics: PerformanceMetrics[]): Promise<DiagnosticReport['performance']> {
    const bottlenecks: Bottleneck[] = [];
    const recommendations: string[] = [];
    const trends: PerformanceTrend[] = [];

    if (metrics.length < 2) {
      return { bottlenecks, recommendations, trends };
    }

    const latest = metrics[metrics.length - 1];
    const previous = metrics[metrics.length - 2];

    // æ£€æµ‹ç“¶é¢ˆ
    if (latest.cpu.usage > 80) {
      bottlenecks.push({
        type: 'CPU',
        description: 'CPUä½¿ç”¨ç‡æŒç»­è¿‡é«˜',
        impact: 'high',
        suggestion: 'è€ƒè™‘ä¼˜åŒ–ä»£ç æˆ–å¢åŠ è®¡ç®—èµ„æº'
      });
    }

    // ç”Ÿæˆå»ºè®®
    if (latest.memory.usage > 85) {
      recommendations.push('ç›‘æ§å†…å­˜æ³„æ¼ï¼Œè€ƒè™‘å¢åŠ å†…å­˜é™åˆ¶');
    }

    if (latest.latency.avg > 500) {
      recommendations.push('ä¼˜åŒ–è¯·æ±‚å¤„ç†é€»è¾‘ï¼Œå‡å°‘å“åº”æ—¶é—´');
    }

    // åˆ†æè¶‹åŠ¿
    const cpuChange = ((latest.cpu.usage - previous.cpu.usage) / previous.cpu.usage) * 100;
    trends.push({
      metric: 'CPUä½¿ç”¨ç‡',
      direction: cpuChange > 5 ? 'degrading' : cpuChange < -5 ? 'improving' : 'stable',
      change: cpuChange,
      period: 'æœ€è¿‘1ä¸ªå‘¨æœŸ'
    });

    return { bottlenecks, recommendations, trends };
  }

  private async performHealthChecks(serverId: string): Promise<DiagnosticReport['health']> {
    const checks: HealthCheck[] = [];
    const warnings: string[] = [];
    const errors: string[] = [];

    // è¿æ¥æ£€æŸ¥
    const connectionStart = performance.now();
    try {
      // è¿™é‡Œåº”è¯¥å®é™…æµ‹è¯•æœåŠ¡å™¨è¿æ¥
      const connectionTime = performance.now() - connectionStart;
      checks.push({
        name: 'è¿æ¥æµ‹è¯•',
        status: connectionTime < 1000 ? 'pass' : 'warn',
        message: `è¿æ¥æ—¶é—´: ${connectionTime.toFixed(2)}ms`,
        duration: connectionTime
      });
    } catch (error) {
      checks.push({
        name: 'è¿æ¥æµ‹è¯•',
        status: 'fail',
        message: `è¿æ¥å¤±è´¥: ${error}`,
        duration: performance.now() - connectionStart
      });
      errors.push('æœåŠ¡å™¨è¿æ¥å¤±è´¥');
    }

    return { checks, warnings, errors };
  }

  private async analyzeResources(metrics: PerformanceMetrics[]): Promise<DiagnosticReport['resources']> {
    if (metrics.length === 0) {
      throw new Error('æ— æ³•åˆ†æèµ„æºä½¿ç”¨æƒ…å†µï¼šç¼ºå°‘æŒ‡æ ‡æ•°æ®');
    }

    const latest = metrics[metrics.length - 1];

    const utilization: ResourceUtilization = {
      cpu: latest.cpu.usage,
      memory: latest.memory.usage,
      disk: 50, // ç®€åŒ–å®ç°
      network: 30
    };

    const capacity: ResourceCapacity = {
      cpu: { current: latest.cpu.usage, max: 100 },
      memory: { current: latest.memory.used, max: latest.memory.total },
      disk: { current: 50, max: 100 },
      network: { current: 30, max: 100 }
    };

    const predictions: ResourcePrediction[] = [];

    // ç®€å•çš„é¢„æµ‹é€»è¾‘
    if (latest.memory.usage > 80) {
      predictions.push({
        resource: 'memory',
        timeToCapacity: 24, // 24å°æ—¶
        confidence: 0.7,
        recommendation: 'ç›‘æ§å†…å­˜ä½¿ç”¨è¶‹åŠ¿ï¼Œè€ƒè™‘æ‰©å®¹'
      });
    }

    return { utilization, capacity, predictions };
  }

  private async cleanupOldMetrics(): Promise<void> {
    const cutoff = new Date(Date.now() - this.config.retentionPeriod);
    
    for (const [serverId, serverMetrics] of this.metrics.entries()) {
      const filtered = serverMetrics.filter(metric => metric.timestamp > cutoff);
      this.metrics.set(serverId, filtered);
    }
  }

  private async saveMetrics(): Promise<void> {
    try {
      const allMetrics = Object.fromEntries(this.metrics);
      await this.cacheManager.set('performance_metrics', allMetrics, 86400);
    } catch (error) {
      console.warn('ä¿å­˜æ€§èƒ½æŒ‡æ ‡å¤±è´¥:', error);
    }
  }
}

interface MonitoringConfig {
  collectInterval: number;
  retentionPeriod: number;
  alertThresholds: {
    cpu: number;
    memory: number;
    latency: number;
    errorRate: number;
    throughput: number;
  };
  enableDetailedMetrics: boolean;
  enablePredictions: boolean;
}

export default MCPPerformanceMonitor;