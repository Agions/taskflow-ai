# AIç¼–æ’å™¨ API

## æ¦‚è¿°

AIç¼–æ’å™¨è´Ÿè´£ç®¡ç†å’Œåè°ƒå¤šä¸ªAIæ¨¡å‹ï¼Œæä¾›æ™ºèƒ½æ¨¡å‹é€‰æ‹©ã€è´Ÿè½½å‡è¡¡ã€æ•…éšœè½¬ç§»ç­‰åŠŸèƒ½ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»AIç¼–æ’å™¨çš„APIæ¥å£å’Œä½¿ç”¨æ–¹æ³•ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```typescript
interface AIOrchestrator {
  // æ¨¡å‹ç®¡ç†
  registerModel(model: AIModel): Promise<void>
  unregisterModel(modelId: string): Promise<void>
  getAvailableModels(): Promise<AIModel[]>
  
  // æ™ºèƒ½å¤„ç†
  processText(text: string, options: ProcessingOptions): Promise<ProcessingResult>
  selectOptimalModel(task: string, context: ProcessingContext): Promise<string>
  
  // è´Ÿè½½å‡è¡¡
  balanceLoad(models: string[]): Promise<string>
  getModelLoad(modelId: string): Promise<ModelLoad>
  
  // å¥åº·æ£€æŸ¥
  healthCheck(modelId?: string): Promise<HealthStatus>
  testConnection(modelId: string): Promise<ConnectionResult>
  
  // æ€§èƒ½ç›‘æ§
  getPerformanceMetrics(modelId?: string): Promise<PerformanceMetrics>
  getUsageStatistics(period?: TimePeriod): Promise<UsageStatistics>
}
```

## ğŸ¤– æ¨¡å‹ç®¡ç†

### registerModel

æ³¨å†ŒAIæ¨¡å‹ã€‚

```typescript
async registerModel(model: AIModel): Promise<void>
```

**ç¤ºä¾‹**:
```typescript
import { AIOrchestrator, AIModel } from 'taskflow-ai'

const orchestrator = new AIOrchestrator()

// æ³¨å†ŒDeepSeekæ¨¡å‹
await orchestrator.registerModel({
  id: 'deepseek',
  name: 'DeepSeek Chat',
  provider: 'deepseek',
  endpoint: 'https://api.deepseek.com/v1/chat/completions',
  apiKey: process.env.DEEPSEEK_API_KEY,
  capabilities: ['text-generation', 'code-analysis', 'reasoning'],
  limits: {
    maxTokens: 4000,
    requestsPerMinute: 60,
    tokensPerMinute: 100000
  },
  pricing: {
    inputTokens: 0.0014,  // per 1K tokens
    outputTokens: 0.0028
  }
})

// æ³¨å†Œæ™ºè°±AIæ¨¡å‹
await orchestrator.registerModel({
  id: 'zhipu',
  name: 'GLM-4',
  provider: 'zhipu',
  endpoint: 'https://open.bigmodel.cn/api/paas/v4/chat/completions',
  apiKey: process.env.ZHIPU_API_KEY,
  capabilities: ['text-generation', 'chinese-understanding', 'reasoning'],
  limits: {
    maxTokens: 8000,
    requestsPerMinute: 100,
    tokensPerMinute: 150000
  }
})
```

### getAvailableModels

è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ã€‚

```typescript
async getAvailableModels(): Promise<AIModel[]>
```

**ç¤ºä¾‹**:
```typescript
const models = await orchestrator.getAvailableModels()

console.log('å¯ç”¨æ¨¡å‹:')
models.forEach(model => {
  console.log(`- ${model.name} (${model.id})`)
  console.log(`  èƒ½åŠ›: ${model.capabilities.join(', ')}`)
  console.log(`  çŠ¶æ€: ${model.status}`)
  console.log(`  è´Ÿè½½: ${model.currentLoad}%`)
})
```

## ğŸ§  æ™ºèƒ½å¤„ç†

### processText

å¤„ç†æ–‡æœ¬å†…å®¹ã€‚

```typescript
async processText(
  text: string, 
  options: ProcessingOptions
): Promise<ProcessingResult>
```

**ç¤ºä¾‹**:
```typescript
// åŸºæœ¬æ–‡æœ¬å¤„ç†
const result = await orchestrator.processText(
  'PRDæ–‡æ¡£å†…å®¹...',
  {
    task: 'prd-analysis',
    preferredModel: 'deepseek',
    fallbackModels: ['zhipu', 'qwen'],
    maxTokens: 2000,
    temperature: 0.7
  }
)

// å¤šæ¨¡å‹å¯¹æ¯”å¤„ç†
const comparison = await orchestrator.processText(
  'PRDæ–‡æ¡£å†…å®¹...',
  {
    task: 'prd-analysis',
    multiModel: true,
    models: ['deepseek', 'zhipu', 'qwen'],
    compareResults: true
  }
)

console.log('å¤„ç†ç»“æœ:')
console.log(`- ä½¿ç”¨æ¨¡å‹: ${result.modelUsed}`)
console.log(`- å¤„ç†æ—¶é—´: ${result.processingTime}ms`)
console.log(`- ç½®ä¿¡åº¦: ${result.confidence}`)
console.log(`- ç»“æœ: ${result.content}`)
```

### selectOptimalModel

é€‰æ‹©æœ€ä¼˜æ¨¡å‹ã€‚

```typescript
async selectOptimalModel(
  task: string, 
  context: ProcessingContext
): Promise<string>
```

**ç¤ºä¾‹**:
```typescript
// æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æ¨¡å‹
const modelForCode = await orchestrator.selectOptimalModel(
  'code-analysis',
  {
    language: 'typescript',
    complexity: 'medium',
    domain: 'web-development'
  }
)

const modelForBusiness = await orchestrator.selectOptimalModel(
  'business-analysis',
  {
    language: 'chinese',
    domain: 'e-commerce',
    documentType: 'requirements'
  }
)

console.log(`ä»£ç åˆ†ææ¨èæ¨¡å‹: ${modelForCode}`)
console.log(`ä¸šåŠ¡åˆ†ææ¨èæ¨¡å‹: ${modelForBusiness}`)
```

## âš–ï¸ è´Ÿè½½å‡è¡¡

### balanceLoad

è´Ÿè½½å‡è¡¡é€‰æ‹©æ¨¡å‹ã€‚

```typescript
async balanceLoad(models: string[]): Promise<string>
```

**ç¤ºä¾‹**:
```typescript
// åœ¨å¤šä¸ªæ¨¡å‹é—´è¿›è¡Œè´Ÿè½½å‡è¡¡
const availableModels = ['deepseek', 'zhipu', 'qwen']
const selectedModel = await orchestrator.balanceLoad(availableModels)

console.log(`è´Ÿè½½å‡è¡¡é€‰æ‹©çš„æ¨¡å‹: ${selectedModel}`)

// è·å–å„æ¨¡å‹å½“å‰è´Ÿè½½
for (const modelId of availableModels) {
  const load = await orchestrator.getModelLoad(modelId)
  console.log(`${modelId} è´Ÿè½½: ${load.currentRequests}/${load.maxRequests}`)
}
```

### getModelLoad

è·å–æ¨¡å‹è´Ÿè½½ä¿¡æ¯ã€‚

```typescript
async getModelLoad(modelId: string): Promise<ModelLoad>
```

**ç¤ºä¾‹**:
```typescript
const load = await orchestrator.getModelLoad('deepseek')

console.log(`DeepSeek æ¨¡å‹è´Ÿè½½:`)
console.log(`- å½“å‰è¯·æ±‚æ•°: ${load.currentRequests}`)
console.log(`- æœ€å¤§è¯·æ±‚æ•°: ${load.maxRequests}`)
console.log(`- è´Ÿè½½ç™¾åˆ†æ¯”: ${load.loadPercentage}%`)
console.log(`- å¹³å‡å“åº”æ—¶é—´: ${load.averageResponseTime}ms`)
console.log(`- é˜Ÿåˆ—é•¿åº¦: ${load.queueLength}`)
```

## ğŸ¥ å¥åº·æ£€æŸ¥

### healthCheck

æ£€æŸ¥æ¨¡å‹å¥åº·çŠ¶æ€ã€‚

```typescript
async healthCheck(modelId?: string): Promise<HealthStatus>
```

**ç¤ºä¾‹**:
```typescript
// æ£€æŸ¥æ‰€æœ‰æ¨¡å‹å¥åº·çŠ¶æ€
const overallHealth = await orchestrator.healthCheck()

console.log(`ç³»ç»Ÿå¥åº·çŠ¶æ€: ${overallHealth.status}`)
console.log(`å¯ç”¨æ¨¡å‹æ•°: ${overallHealth.availableModels}/${overallHealth.totalModels}`)

// æ£€æŸ¥ç‰¹å®šæ¨¡å‹
const deepseekHealth = await orchestrator.healthCheck('deepseek')

if (deepseekHealth.status === 'healthy') {
  console.log('DeepSeek æ¨¡å‹è¿è¡Œæ­£å¸¸')
} else {
  console.log(`DeepSeek æ¨¡å‹å¼‚å¸¸: ${deepseekHealth.issues.join(', ')}`)
}
```

### testConnection

æµ‹è¯•æ¨¡å‹è¿æ¥ã€‚

```typescript
async testConnection(modelId: string): Promise<ConnectionResult>
```

**ç¤ºä¾‹**:
```typescript
const connectionTest = await orchestrator.testConnection('zhipu')

console.log(`æ™ºè°±AI è¿æ¥æµ‹è¯•:`)
console.log(`- è¿æ¥çŠ¶æ€: ${connectionTest.success ? 'æˆåŠŸ' : 'å¤±è´¥'}`)
console.log(`- å“åº”æ—¶é—´: ${connectionTest.responseTime}ms`)
console.log(`- APIçŠ¶æ€: ${connectionTest.apiStatus}`)

if (!connectionTest.success) {
  console.log(`é”™è¯¯ä¿¡æ¯: ${connectionTest.error}`)
}
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### getPerformanceMetrics

è·å–æ€§èƒ½æŒ‡æ ‡ã€‚

```typescript
async getPerformanceMetrics(modelId?: string): Promise<PerformanceMetrics>
```

**ç¤ºä¾‹**:
```typescript
// è·å–æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½æŒ‡æ ‡
const overallMetrics = await orchestrator.getPerformanceMetrics()

console.log('æ•´ä½“æ€§èƒ½æŒ‡æ ‡:')
console.log(`- å¹³å‡å“åº”æ—¶é—´: ${overallMetrics.averageResponseTime}ms`)
console.log(`- æˆåŠŸç‡: ${overallMetrics.successRate}%`)
console.log(`- ååé‡: ${overallMetrics.throughput} è¯·æ±‚/åˆ†é’Ÿ`)

// è·å–ç‰¹å®šæ¨¡å‹çš„æ€§èƒ½æŒ‡æ ‡
const deepseekMetrics = await orchestrator.getPerformanceMetrics('deepseek')

console.log('DeepSeek æ€§èƒ½æŒ‡æ ‡:')
console.log(`- å“åº”æ—¶é—´: ${deepseekMetrics.averageResponseTime}ms`)
console.log(`- æˆåŠŸç‡: ${deepseekMetrics.successRate}%`)
console.log(`- é”™è¯¯ç‡: ${deepseekMetrics.errorRate}%`)
console.log(`- ç¼“å­˜å‘½ä¸­ç‡: ${deepseekMetrics.cacheHitRate}%`)
```

### getUsageStatistics

è·å–ä½¿ç”¨ç»Ÿè®¡ã€‚

```typescript
async getUsageStatistics(period?: TimePeriod): Promise<UsageStatistics>
```

**ç¤ºä¾‹**:
```typescript
// è·å–æœ¬æœˆä½¿ç”¨ç»Ÿè®¡
const monthlyStats = await orchestrator.getUsageStatistics({
  start: new Date('2024-01-01'),
  end: new Date('2024-01-31')
})

console.log('æœ¬æœˆä½¿ç”¨ç»Ÿè®¡:')
console.log(`- æ€»è¯·æ±‚æ•°: ${monthlyStats.totalRequests}`)
console.log(`- æ€»Tokenæ•°: ${monthlyStats.totalTokens}`)
console.log(`- æ€»è´¹ç”¨: $${monthlyStats.totalCost}`)

console.log('æŒ‰æ¨¡å‹åˆ†å¸ƒ:')
monthlyStats.byModel.forEach(stat => {
  console.log(`- ${stat.modelId}: ${stat.requests} è¯·æ±‚, $${stat.cost}`)
})

console.log('æŒ‰ä»»åŠ¡ç±»å‹åˆ†å¸ƒ:')
monthlyStats.byTask.forEach(stat => {
  console.log(`- ${stat.taskType}: ${stat.requests} è¯·æ±‚`)
})
```

## ğŸ”§ ç±»å‹å®šä¹‰

### AIModel

AIæ¨¡å‹å®šä¹‰ã€‚

```typescript
interface AIModel {
  // åŸºæœ¬ä¿¡æ¯
  id: string
  name: string
  provider: string
  version?: string
  
  // è¿æ¥ä¿¡æ¯
  endpoint: string
  apiKey: string
  headers?: Record<string, string>
  
  // èƒ½åŠ›æè¿°
  capabilities: ModelCapability[]
  supportedTasks: string[]
  
  // é™åˆ¶å’Œé…é¢
  limits: {
    maxTokens: number
    requestsPerMinute: number
    tokensPerMinute: number
    maxConcurrentRequests?: number
  }
  
  // å®šä»·ä¿¡æ¯
  pricing?: {
    inputTokens: number   // per 1K tokens
    outputTokens: number  // per 1K tokens
    fixedCost?: number    // per request
  }
  
  // çŠ¶æ€ä¿¡æ¯
  status: ModelStatus
  currentLoad: number
  lastHealthCheck: Date
  
  // é…ç½®å‚æ•°
  defaultParams: {
    temperature?: number
    maxTokens?: number
    topP?: number
    frequencyPenalty?: number
  }
}
```

### ProcessingOptions

å¤„ç†é€‰é¡¹ã€‚

```typescript
interface ProcessingOptions {
  // ä»»åŠ¡ç±»å‹
  task: string
  
  // æ¨¡å‹é€‰æ‹©
  preferredModel?: string
  fallbackModels?: string[]
  multiModel?: boolean
  models?: string[]
  
  // å¤„ç†å‚æ•°
  maxTokens?: number
  temperature?: number
  topP?: number
  
  // è´¨é‡æ§åˆ¶
  compareResults?: boolean
  minConfidence?: number
  maxRetries?: number
  
  // ç¼“å­˜æ§åˆ¶
  useCache?: boolean
  cacheKey?: string
  cacheTTL?: number
  
  // å›è°ƒå‡½æ•°
  onProgress?: (progress: ProcessingProgress) => void
  onModelSelected?: (modelId: string) => void
  onError?: (error: ProcessingError) => void
}
```

### ProcessingResult

å¤„ç†ç»“æœã€‚

```typescript
interface ProcessingResult {
  // åŸºæœ¬ç»“æœ
  success: boolean
  content: string
  
  // æ¨¡å‹ä¿¡æ¯
  modelUsed: string
  modelsAttempted: string[]
  
  // æ€§èƒ½æŒ‡æ ‡
  processingTime: number
  tokenUsage: {
    input: number
    output: number
    total: number
  }
  
  // è´¨é‡æŒ‡æ ‡
  confidence: number
  quality: QualityMetrics
  
  // æˆæœ¬ä¿¡æ¯
  cost: {
    amount: number
    currency: string
    breakdown: CostBreakdown
  }
  
  // å…ƒæ•°æ®
  metadata: {
    timestamp: Date
    requestId: string
    version: string
  }
  
  // é”™è¯¯ä¿¡æ¯
  errors?: ProcessingError[]
  warnings?: ProcessingWarning[]
}
```

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```typescript
import { AIOrchestrator } from 'taskflow-ai'

async function basicUsage() {
  const orchestrator = new AIOrchestrator()
  
  // å¤„ç†PRDæ–‡æ¡£
  const result = await orchestrator.processText(
    'PRDæ–‡æ¡£å†…å®¹...',
    {
      task: 'prd-analysis',
      preferredModel: 'deepseek',
      maxTokens: 2000
    }
  )
  
  if (result.success) {
    console.log('è§£æç»“æœ:', result.content)
    console.log('ä½¿ç”¨æ¨¡å‹:', result.modelUsed)
    console.log('å¤„ç†æ—¶é—´:', result.processingTime, 'ms')
    console.log('è´¹ç”¨:', result.cost.amount, result.cost.currency)
  } else {
    console.error('å¤„ç†å¤±è´¥:', result.errors)
  }
}
```

### å¤šæ¨¡å‹ååŒ

```typescript
async function multiModelProcessing() {
  const orchestrator = new AIOrchestrator()
  
  // å¤šæ¨¡å‹ååŒå¤„ç†
  const result = await orchestrator.processText(
    'å¤æ‚çš„PRDæ–‡æ¡£å†…å®¹...',
    {
      task: 'complex-analysis',
      multiModel: true,
      models: ['deepseek', 'zhipu', 'qwen'],
      compareResults: true,
      minConfidence: 0.8
    }
  )
  
  console.log('å¤šæ¨¡å‹å¤„ç†ç»“æœ:')
  console.log(`- ä¸»è¦ç»“æœ: ${result.content}`)
  console.log(`- ç½®ä¿¡åº¦: ${result.confidence}`)
  console.log(`- å°è¯•çš„æ¨¡å‹: ${result.modelsAttempted.join(', ')}`)
  console.log(`- æœ€ç»ˆé€‰æ‹©: ${result.modelUsed}`)
  
  // å¦‚æœæœ‰å¯¹æ¯”ç»“æœ
  if (result.metadata.comparisons) {
    console.log('æ¨¡å‹å¯¹æ¯”ç»“æœ:')
    result.metadata.comparisons.forEach(comp => {
      console.log(`- ${comp.modelId}: ç½®ä¿¡åº¦ ${comp.confidence}`)
    })
  }
}
```

### æ™ºèƒ½æ¨¡å‹é€‰æ‹©

```typescript
async function intelligentModelSelection() {
  const orchestrator = new AIOrchestrator()
  
  // é…ç½®æ™ºèƒ½é€‰æ‹©ç­–ç•¥
  await orchestrator.configureSelection({
    strategy: 'performance-cost-balanced',
    factors: {
      performance: 0.4,
      cost: 0.3,
      availability: 0.3
    },
    learningEnabled: true
  })
  
  // å¤„ç†ä¸åŒç±»å‹çš„ä»»åŠ¡
  const tasks = [
    { content: 'æŠ€æœ¯è§„æ ¼æ–‡æ¡£...', type: 'technical-analysis' },
    { content: 'ä¸šåŠ¡éœ€æ±‚æ–‡æ¡£...', type: 'business-analysis' },
    { content: 'ä»£ç å®¡æŸ¥å†…å®¹...', type: 'code-review' }
  ]
  
  for (const task of tasks) {
    const optimalModel = await orchestrator.selectOptimalModel(
      task.type,
      { content: task.content }
    )
    
    console.log(`${task.type} æ¨èæ¨¡å‹: ${optimalModel}`)
    
    const result = await orchestrator.processText(task.content, {
      task: task.type,
      preferredModel: optimalModel
    })
    
    // è®°å½•ç»“æœç”¨äºå­¦ä¹ 
    await orchestrator.recordResult(task.type, optimalModel, result)
  }
}
```

### æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

```typescript
async function performanceMonitoring() {
  const orchestrator = new AIOrchestrator()
  
  // å¯ç”¨å®æ—¶ç›‘æ§
  orchestrator.enableMonitoring({
    interval: 60000, // 1åˆ†é’Ÿ
    metrics: ['response-time', 'success-rate', 'cost', 'load'],
    alerts: {
      responseTimeThreshold: 5000,
      errorRateThreshold: 0.05,
      costThreshold: 100
    }
  })
  
  // ç›‘å¬æ€§èƒ½äº‹ä»¶
  orchestrator.on('performanceAlert', (alert) => {
    console.log(`æ€§èƒ½å‘Šè­¦: ${alert.type} - ${alert.message}`)
    
    if (alert.type === 'high-response-time') {
      // è‡ªåŠ¨åˆ‡æ¢åˆ°æ›´å¿«çš„æ¨¡å‹
      orchestrator.temporaryModelSwitch(alert.modelId, 'faster-model')
    }
  })
  
  // å®šæœŸç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
  setInterval(async () => {
    const metrics = await orchestrator.getPerformanceMetrics()
    console.log('æ€§èƒ½æŠ¥å‘Š:', metrics)
    
    // è‡ªåŠ¨ä¼˜åŒ–å»ºè®®
    const suggestions = await orchestrator.getOptimizationSuggestions()
    if (suggestions.length > 0) {
      console.log('ä¼˜åŒ–å»ºè®®:', suggestions)
    }
  }, 3600000) // æ¯å°æ—¶
}
```

## ğŸ”„ äº‹ä»¶å’Œé’©å­

### æ¨¡å‹äº‹ä»¶

```typescript
orchestrator.on('modelRegistered', (model: AIModel) => {
  console.log(`æ¨¡å‹æ³¨å†Œ: ${model.name}`)
})

orchestrator.on('modelHealthChanged', (modelId: string, status: ModelStatus) => {
  console.log(`æ¨¡å‹ ${modelId} å¥åº·çŠ¶æ€å˜æ›´: ${status}`)
})

orchestrator.on('loadBalanced', (selectedModel: string, availableModels: string[]) => {
  console.log(`è´Ÿè½½å‡è¡¡é€‰æ‹©: ${selectedModel} (å¯é€‰: ${availableModels.join(', ')})`)
})
```

### å¤„ç†äº‹ä»¶

```typescript
orchestrator.on('processingStart', (requestId: string, options: ProcessingOptions) => {
  console.log(`å¼€å§‹å¤„ç†è¯·æ±‚: ${requestId}`)
})

orchestrator.on('processingComplete', (result: ProcessingResult) => {
  console.log(`å¤„ç†å®Œæˆ: ${result.modelUsed}, è€—æ—¶: ${result.processingTime}ms`)
})

orchestrator.on('processingError', (error: ProcessingError) => {
  console.error(`å¤„ç†é”™è¯¯: ${error.message}`)
})
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [PRDè§£æå™¨ API](./prd-parser.md) - PRDæ–‡æ¡£è§£æ
- [ä»»åŠ¡ç®¡ç†å™¨ API](./task-manager.md) - ä»»åŠ¡ç®¡ç†
- [é…ç½®ç®¡ç† API](./config-manager.md) - é…ç½®ç®¡ç†
- [ç±»å‹å®šä¹‰](./types/model.md) - æ¨¡å‹ç›¸å…³ç±»å‹
