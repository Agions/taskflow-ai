/**
 * å‘é‡å­˜å‚¨ç®¡ç†å™¨
 * æ”¯æŒ LanceDBã€Chroma ç­‰å‘é‡æ•°æ®åº“
 */

import * as fs from 'fs-extra';
import * as path from 'path';
import {
  VectorStore,
  VectorStoreConnection,
  DocumentChunk,
  RetrievedChunk,
  RetrievalOptions,
  FilterCondition,
  IndexStatus
} from '../types';
import { EmbeddingManager } from '../embedding';

// ç®€åŒ–çš„å‘é‡å­˜å‚¨å®ç°
// å®é™…åº”è¯¥ä½¿ç”¨ LanceDBã€Chroma ç­‰çœŸå®æ•°æ®åº“

interface StoredChunk extends DocumentChunk {
  timestamp: number;
}

export class VectorStoreManager {
  private store: VectorStore;
  private embeddingManager: EmbeddingManager;
  private data: Map<string, StoredChunk> = new Map();
  private dataDir: string;

  constructor(
    store: VectorStore,
    embeddingManager: EmbeddingManager,
    dataDir?: string
  ) {
    this.store = store;
    this.embeddingManager = embeddingManager;
    this.dataDir = dataDir || path.join(process.cwd(), '.taskflow', 'vector-store');
  }

  /**
   * åˆå§‹åŒ–å­˜å‚¨
   */
  async initialize(): Promise<void> {
    await fs.ensureDir(this.dataDir);

    // åŠ è½½å·²æœ‰æ•°æ®
    await this.loadData();

    console.log(`âœ… Vector store initialized: ${this.store.type}`);
  }

  /**
   * æ·»åŠ æ–‡æ¡£å—
   */
  async addChunks(chunks: DocumentChunk[]): Promise<void> {
    for (const chunk of chunks) {
      const storedChunk: StoredChunk = {
        ...chunk,
        timestamp: Date.now()
      };
      this.data.set(chunk.id, storedChunk);
    }

    // ä¿å­˜åˆ°ç£ç›˜
    await this.saveData();

    console.log(`âœ… Added ${chunks.length} chunks to vector store`);
  }

  /**
   * åˆ é™¤æ–‡æ¡£å—
   */
  async deleteChunks(documentId: string): Promise<void> {
    let deleted = 0;

    for (const [id, chunk] of this.data) {
      if (chunk.documentId === documentId) {
        this.data.delete(id);
        deleted++;
      }
    }

    await this.saveData();

    console.log(`âœ… Deleted ${deleted} chunks for document ${documentId}`);
  }

  /**
   * ç›¸ä¼¼åº¦æœç´¢
   */
  async search(
    query: string,
    options: RetrievalOptions = {}
  ): Promise<RetrievedChunk[]> {
    const startTime = Date.now();

    const {
      topK = 5,
      threshold = 0.7,
      filters = [],
      rerank = false
    } = options;

    // ç”ŸæˆæŸ¥è¯¢åµŒå…¥
    const queryEmbedding = await this.embeddingManager.embed(query);

    // è®¡ç®—ç›¸ä¼¼åº¦
    let results: RetrievedChunk[] = [];

    for (const chunk of this.data.values()) {
      // åº”ç”¨è¿‡æ»¤å™¨
      if (!this.matchesFilters(chunk, filters)) {
        continue;
      }

      // è®¡ç®—ç›¸ä¼¼åº¦
      const score = this.embeddingManager.cosineSimilarity(
        queryEmbedding,
        chunk.embedding
      );

      if (score >= threshold) {
        results.push({
          chunk,
          score,
          distance: 1 - score
        });
      }
    }

    // æ’åº
    results.sort((a, b) => b.score - a.score);

    // å–å‰ K ä¸ª
    results = results.slice(0, topK);

    // é‡æ’åºï¼ˆç®€åŒ–å®ç°ï¼‰
    if (rerank) {
      results = this.rerank(results, query);
    }

    const latency = Date.now() - startTime;
    console.log(`ğŸ” Search completed: ${results.length} results in ${latency}ms`);

    return results;
  }

  /**
   * æ··åˆæœç´¢ï¼ˆå‘é‡ + å…³é”®è¯ï¼‰
   */
  async hybridSearch(
    query: string,
    options: RetrievalOptions = {}
  ): Promise<RetrievedChunk[]> {
    const vectorResults = await this.search(query, options);

    // å…³é”®è¯æœç´¢
    const keywordResults = this.keywordSearch(query, options);

    // åˆå¹¶ç»“æœ
    const merged = this.mergeResults(vectorResults, keywordResults);

    return merged.slice(0, options.topK || 5);
  }

  /**
   * è·å–ç´¢å¼•çŠ¶æ€
   */
  async getStatus(): Promise<IndexStatus> {
    const documents = new Set<string>();
    let totalChunks = 0;

    for (const chunk of this.data.values()) {
      documents.add(chunk.documentId);
      totalChunks++;
    }

    // è®¡ç®—å­˜å‚¨å¤§å°
    const dataFile = path.join(this.dataDir, `${this.store.connection.collection || 'default'}.json`);
    let size = 0;
    if (await fs.pathExists(dataFile)) {
      const stats = await fs.stat(dataFile);
      size = stats.size;
    }

    return {
      totalDocuments: documents.size,
      totalChunks,
      indexedAt: new Date(),
      lastUpdated: new Date(),
      size
    };
  }

  /**
   * æ¸…ç©ºå­˜å‚¨
   */
  async clear(): Promise<void> {
    this.data.clear();
    await this.saveData();
    console.log('ğŸ—‘ï¸  Vector store cleared');
  }

  /**
   * å…³é”®è¯æœç´¢
   */
  private keywordSearch(query: string, options: RetrievalOptions): RetrievedChunk[] {
    const keywords = query.toLowerCase().split(/\s+/);
    const results: RetrievedChunk[] = [];

    for (const chunk of this.data.values()) {
      const content = chunk.content.toLowerCase();
      let matches = 0;

      for (const keyword of keywords) {
        if (content.includes(keyword)) {
          matches++;
        }
      }

      if (matches > 0) {
        const score = matches / keywords.length;
        if (score >= (options.threshold || 0.3)) {
          results.push({
            chunk,
            score,
            distance: 1 - score
          });
        }
      }
    }

    results.sort((a, b) => b.score - a.score);
    return results.slice(0, options.topK || 5);
  }

  /**
   * åˆå¹¶ç»“æœ
   */
  private mergeResults(
    vectorResults: RetrievedChunk[],
    keywordResults: RetrievedChunk[]
  ): RetrievedChunk[] {
    const merged = new Map<string, RetrievedChunk>();

    // æ·»åŠ å‘é‡æœç´¢ç»“æœ
    for (const result of vectorResults) {
      merged.set(result.chunk.id, {
        ...result,
        score: result.score * 0.7 // å‘é‡æƒé‡ 0.7
      });
    }

    // æ·»åŠ å…³é”®è¯æœç´¢ç»“æœ
    for (const result of keywordResults) {
      const existing = merged.get(result.chunk.id);
      if (existing) {
        existing.score += result.score * 0.3; // å…³é”®è¯æƒé‡ 0.3
      } else {
        merged.set(result.chunk.id, {
          ...result,
          score: result.score * 0.3
        });
      }
    }

    return Array.from(merged.values()).sort((a, b) => b.score - a.score);
  }

  /**
   * é‡æ’åº
   */
  private rerank(results: RetrievedChunk[], query: string): RetrievedChunk[] {
    // ç®€åŒ–å®ç°ï¼šä½¿ç”¨å…³é”®è¯åŒ¹é…åº¦è¿›è¡Œé‡æ’åº
    const keywords = query.toLowerCase().split(/\s+/);

    return results.map(result => {
      const content = result.chunk.content.toLowerCase();
      let keywordScore = 0;

      for (const keyword of keywords) {
        const count = (content.match(new RegExp(keyword, 'g')) || []).length;
        keywordScore += count;
      }

      // ç»“åˆå‘é‡ç›¸ä¼¼åº¦å’Œå…³é”®è¯åŒ¹é…
      const combinedScore = result.score * 0.8 + Math.min(keywordScore * 0.1, 0.2);

      return {
        ...result,
        score: combinedScore
      };
    }).sort((a, b) => b.score - a.score);
  }

  /**
   * æ£€æŸ¥æ˜¯å¦åŒ¹é…è¿‡æ»¤å™¨
   */
  private matchesFilters(chunk: DocumentChunk, filters: FilterCondition[]): boolean {
    if (filters.length === 0) return true;

    return filters.every(filter => {
      const value = this.getFieldValue(chunk, filter.field);

      switch (filter.operator) {
        case 'eq':
          return value === filter.value;
        case 'ne':
          return value !== filter.value;
        case 'gt':
          return value > filter.value;
        case 'gte':
          return value >= filter.value;
        case 'lt':
          return value < filter.value;
        case 'lte':
          return value <= filter.value;
        case 'in':
          return Array.isArray(filter.value) && filter.value.includes(value);
        case 'contains':
          return String(value).includes(String(filter.value));
        default:
          return true;
      }
    });
  }

  /**
   * è·å–å­—æ®µå€¼
   */
  private getFieldValue(chunk: DocumentChunk, field: string): any {
    const parts = field.split('.');
    let value: any = chunk;

    for (const part of parts) {
      if (value && typeof value === 'object') {
        value = value[part];
      } else {
        return undefined;
      }
    }

    return value;
  }

  /**
   * ä¿å­˜æ•°æ®
   */
  private async saveData(): Promise<void> {
    const dataFile = path.join(this.dataDir, `${this.store.connection.collection || 'default'}.json`);
    const data = Array.from(this.data.values());
    await fs.writeJson(dataFile, data, { spaces: 2 });
  }

  /**
   * åŠ è½½æ•°æ®
   */
  private async loadData(): Promise<void> {
    const dataFile = path.join(this.dataDir, `${this.store.connection.collection || 'default'}.json`);

    if (await fs.pathExists(dataFile)) {
      try {
        const data: StoredChunk[] = await fs.readJson(dataFile);
        for (const chunk of data) {
          this.data.set(chunk.id, chunk);
        }
        console.log(`ğŸ“š Loaded ${data.length} chunks from storage`);
      } catch (error) {
        console.warn('Failed to load vector store data:', error);
      }
    }
  }
}

export default VectorStoreManager;
